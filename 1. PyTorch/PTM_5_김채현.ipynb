{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [PTM] Section 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 여러 데이터 소스를 통합 데이터셋으로 합치기\n",
    "1. 원본 데이터 읽기\n",
    "2. 전처리\n",
    "\n",
    "원본 CT 스캔 데이터에 달아놓은 어노테이션 목록으로 훈련 샘플 만들기\n",
    "\n",
    "### 10.1 원본 CT 데이터 파일\n",
    "- `.mhd`: 메타데이터 헤더 정보가 포함\n",
    "- `.raw`: 3차원 배열을 만들 원본 데이터 바이트\n",
    "- 각 파일 이름은 `시리즈 UID`라고 불리는 CT 스캔 단일 식별자로 시작\n",
    "  - UID 1.2.3 = 1.2.3.mhd + 1.2.3.raw\n",
    "- 데이터를 제한하거나 잘라서 모델에 노이즈가 끼지 않게하는 것도 중요\n",
    "\n",
    "### 10.2 LUNA 애노테이션 데이터 파싱\n",
    "- LUNA에서 제공하는 `csv` 파일을 먼저 파싱해, 각 CT 스캔 중 관심 있는 부분을 파악할 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r\"C:\\Users\\spec3\\OneDrive\\바탕 화면\\Dev\\RhythmStudy\\1. PyTorch\\data\\part2\\luna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551065, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 책에서는 bash로 출력하지만, 판다스로 대체\n",
    "candidates = pd.read_csv(os.path.join(root_path, \"candidates.csv\"))\n",
    "\n",
    "candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-56.08</td>\n",
       "      <td>-67.85</td>\n",
       "      <td>-311.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>53.21</td>\n",
       "      <td>-244.41</td>\n",
       "      <td>-245.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>103.66</td>\n",
       "      <td>-121.80</td>\n",
       "      <td>-286.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid  coordX  coordY  coordZ  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  -56.08  -67.85 -311.92   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...   53.21 -244.41 -245.17   \n",
       "2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  103.66 -121.80 -286.62   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549714\n",
       "1      1351\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 분포\n",
    "# 0: 결절X / 1: 결절O\n",
    "candidates[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1186, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결절로 플래그된 후보들에 대한 정보\n",
    "annotations = pd.read_csv(os.path.join(root_path, \"annotations.csv\"))\n",
    "\n",
    "annotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>diameter_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-128.699421</td>\n",
       "      <td>-175.319272</td>\n",
       "      <td>-298.387506</td>\n",
       "      <td>5.651471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>103.783651</td>\n",
       "      <td>-211.925149</td>\n",
       "      <td>-227.121250</td>\n",
       "      <td>4.224708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...</td>\n",
       "      <td>69.639017</td>\n",
       "      <td>-140.944586</td>\n",
       "      <td>876.374496</td>\n",
       "      <td>5.786348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid      coordX      coordY  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -128.699421 -175.319272   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  103.783651 -211.925149   \n",
       "2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...   69.639017 -140.944586   \n",
       "\n",
       "       coordZ  diameter_mm  \n",
       "0 -298.387506     5.651471  \n",
       "1 -227.121250     4.224708  \n",
       "2  876.374496     5.786348  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.1 훈련셋과 검증셋\n",
    "- 모든 표준 지도 학습(supervised learning) 작업은 데이터를 훈련셋(training set)과 검증셋(validation set)으로 나눔\n",
    "- 크기 순으로 정렬한 후, 매 N번째에 대해 검증세트로 구성\n",
    "\n",
    "#### 10.2.2 어노테이션 데이터와 후보 데이터 합치기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import collections\n",
    "from collections import namedtuple\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from util.disk import getCache\n",
    "from util.util import XyzTuple, xyz2irc\n",
    "from util.logconf import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전문가의 어노테이션을 나타내는, 나름의 인터페이스\n",
    "# 결절의 상태, 결절의 직겨으 순번, 중심점\n",
    "CandidateInfoTuple = namedtuple(\n",
    "    \"CandidateInfoTuple\",\n",
    "    \"isNodule_bool, diameter_mm, series_uid, center_xyz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보 정보\n",
    "@functools.lru_cache(1) # 표준 인메모리 캐싱 라이브러리\n",
    "# - 일부 데이터 파일은 파싱에 시간이 걸리므로, 함수 호출 결과를 메모리에 캐시\n",
    "# - 인메모리나 온디스크 캐싱을 적절하게 사용하여 데이터 파이프라인 속도를 올려 놓으면 훈련 속도의 개선으로 이어질 수 있음\n",
    "def getCandidateInfoList(requireOnDisk_bool=True):\n",
    "    mhd_list = glob.glob(os.path.join(os.path.expanduser(\"~\"), \"Downloads/*/*/*.mhd\"))\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "    \n",
    "    diameter_dict = {}\n",
    "    with open(os.path.join(root_path, \"annotations.csv\"), \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "            annotationCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "            annotationDiameter_mm = float(row[4])\n",
    "            \n",
    "            diameter_dict.setdefault(series_uid, []).append(\n",
    "                (annotationCenter_xyz, annotationDiameter_mm)\n",
    "            )\n",
    "            \n",
    "    # candidates.csv의 정보를 이용해 전체 후보 리스트 만들기\n",
    "    candidateInfo_list = []\n",
    "    with open(os.path.join(root_path, \"candidates.csv\"), \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "            \n",
    "            if series_uid not in presentOnDisk_set and requireOnDisk_bool: continue\n",
    "            \n",
    "            isNodule_bool = bool(int(row[4]))\n",
    "            candidateCenter_xyz = tuple(float(x) for x in row[1:4])\n",
    "            \n",
    "            candidateDiameter_mm = 0.0\n",
    "            for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "                annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "                for i in range(3):\n",
    "                    delta_mm = abs(candidateCenter_xyz[i] - annotationCenter_xyz[i])\n",
    "                    if delta_mm>annotationDiameter_mm/4: # 바운딩 박스 체크\n",
    "                        break\n",
    "                    else:\n",
    "                        candidateDiameter_mm = annotationDiameter_mm\n",
    "                        break\n",
    "                \n",
    "                candidateInfo_list.append(CandidateInfoTuple(isNodule_bool, candidateDiameter_mm, series_uid, candidateCenter_xyz))\n",
    "    \n",
    "    candidateInfo_list.sort(reverse=True)\n",
    "    return candidateInfo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스로하면 이렇게 될 듯..?\n",
    "diameter_dict_df = {}\n",
    "\n",
    "for idx in range(len(annotations)):\n",
    "    series_uid = annotations.iloc[idx, 0]\n",
    "    annotationCenter_xyz = tuple([float(x) for x in annotations.iloc[idx, 1:4]])\n",
    "    annotationDiameter_mm = float(annotations.iloc[idx, -1])\n",
    "    \n",
    "    diameter_dict_df.setdefault(series_uid, []).append(\n",
    "        (annotationCenter_xyz, annotationDiameter_mm)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 개별 CT 스캔 로딩\n",
    "- 읽어온 CT 데이터를 얻어와 파이썬 객체로 변환해서 3차원 결절 밀도 데이터로 사용할 수 있도록 만드는 작업\n",
    "- 결절 어노테이션 정보는 원본 데이터에서 얻어내고자 하는 영역에 대한 맵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(os.path.join(os.path.expanduser(\"~\"), f\"Downloads/*/*/{series_uid}.mhd\"))[0]\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1 하운스필드 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(os.path.join(os.path.expanduser(\"~\"), f\"Downloads/*/*/{series_uid}.mhd\"))[0]\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "        # HU 제거 (시야에 해당하는 값만 남기고, 이외는 모두 제거)\n",
    "        ct_a.clip(-1000, 1000, ct_a)\n",
    "        \n",
    "        self.serires_uid = series_uid\n",
    "        self.hu_a = ct_a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 환자 좌표계를 사용해 결절 위치 정하기\n",
    "- 통상적으로 모델은 고정된 크기의 입력을 필요로 함 (뉴런 수가 고정되어 있기때문)\n",
    "\n",
    "#### 10.4.1 환자 좌표계\n",
    "- 밀리미터 기반 `(X, Y, Z)`를 복셀 주소 기반 `(I, R, C)`로 변환\n",
    "- `X`는 환자의 왼쪽, `Y`는 뒤쪽(후면), `Z`는 머리(상부)\n",
    "  - 왼쪽-후면-상부(LPS, left-posterior-superior)\n",
    "- 해부학적으로 관심있는 위치를 지정하기 위해 사용\n",
    "- CT 배열과 환자 좌표계 사이의 관계를 정의하는 메타데이터는 파일 헤더에 저장\n",
    "\n",
    "#### 10.4.2. CT 스캔 형태와 복셀 크기\n",
    "- 메르카토르(Mercator)식 세계 지도와 유사하게, 실제 비율을 보기 위해서는 비율 계수(scale factor)를 적용\n",
    "\n",
    "#### 10.4.3 밀리미터를 복셀 주소로 변환하기\n",
    "1. 좌표를 XYZ 체계로 만들기 위해 IRC에서 CRI로 뒤집는다\n",
    "2. 인덱스를 복셀 크기로 확대축소\n",
    "3. 파이썬의 `@`를 이용해 방향을 나타내는 행렬과 행렬곱을 수행\n",
    "4. 기준으로부터 오프셋을 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrcTuple = collections.namedtuple(\"IrcTuple\", [\"index\", \"row\", \"col\"])\n",
    "XyzTuple = collections.namedtuple(\"XyzTuple\", [\"x\", \"y\", \"z\"])\n",
    "\n",
    "def irc2xyz(coord_irc, origin_xyz, vxSize_xyz, direction_a):\n",
    "    cri_a = np.array(coord_irc)[::-1] # 넘파이 배열로 변환하며 순서를 바꿈\n",
    "    origin_a = np.array(origin_xyz)\n",
    "    vxSize_a = np.array(vxSize_xyz)\n",
    "    coords_xyz = (direction_a @ (cri_a * vxSize_a)) + origin_a\n",
    "    return XyzTuple(*coords_xyz)\n",
    "\n",
    "def xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n",
    "    origin_a = np.array(origin_xyz)\n",
    "    vxSize_a = np.array(vxSize_xyz)\n",
    "    coord_a = np.array(coord_xyz)\n",
    "    cri_a = ((coord_a - origin_a) @ np.linalg.inv(direction_a)) / vxSize_a\n",
    "    cri_a = np.round(cri_a)\n",
    "    return IrcTuple(int(cri_a[2])), int(cri_a[1]), int(cri_a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(os.path.join(os.path.expanduser(\"~\"), f\"Downloads/*/*/{series_uid}.mhd\"))[0]\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "        # HU 제거 (시야에 해당하는 값만 남기고, 이외는 모두 제거)\n",
    "        ct_a.clip(-1000, 1000, ct_a)\n",
    "        \n",
    "        self.serires_uid = series_uid\n",
    "        self.hu_a = ct_a\n",
    "        \n",
    "        self.origin_xyz = XyzTuple(*ct_mhd.GetOrigin())\n",
    "        self.vxSize_xyz = XyzTuple(*ct_mhd.GetSpacing())\n",
    "        self.direction_a = np.array(ct_mhd.GetDirection()).reshape(3, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.4 CT 스캔에서 결절 추출하기\n",
    "- 각 후부 영역을 추출해 모델이 한 번에 한 영역에 집중할 수 있도록 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(os.path.join(os.path.expanduser(\"~\"), f\"Downloads/*/*/{series_uid}.mhd\"))[0]\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "        # HU 제거 (시야에 해당하는 값만 남기고, 이외는 모두 제거)\n",
    "        ct_a.clip(-1000, 1000, ct_a)\n",
    "        \n",
    "        self.serires_uid = series_uid\n",
    "        self.hu_a = ct_a\n",
    "        \n",
    "        self.origin_xyz = XyzTuple(*ct_mhd.GetOrigin())\n",
    "        self.vxSize_xyz = XyzTuple(*ct_mhd.GetSpacing())\n",
    "        self.direction_a = np.array(ct_mhd.GetDirection()).reshape(3, 3)\n",
    "        \n",
    "    def getRawCandidate(self, center_xyz, width_irc):\n",
    "        center_irc = xyz2irc(\n",
    "            center_xyz,\n",
    "            self.origin_xyz,\n",
    "            self.vxSize_xyz,\n",
    "            self.direction_a\n",
    "        )\n",
    "        \n",
    "        slice_list = []\n",
    "        for axis, center_val in enumerate(center_irc):\n",
    "            start_ndx = int(round(center_val - width_irc[axis]/2))\n",
    "            end_ndx = int(start_ndx + width_irc[axis])\n",
    "            slice_list.append(slice(start_ndx, end_ndx))\n",
    "        \n",
    "        ct_chunk = self.hu_a[tuple(slice_list)]\n",
    "        \n",
    "        return ct_chunk, center_irc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 간단한 데이터셋 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 val_stride=0,\n",
    "                 isValSet_bool=None,\n",
    "                 series_uid=None,\n",
    "            ):\n",
    "        self.candidateInfo_list = copy.copy(getCandidateInfoList())\n",
    "\n",
    "        if series_uid:\n",
    "            self.candidateInfo_list = [\n",
    "                x for x in self.candidateInfo_list if x.series_uid == series_uid\n",
    "            ]\n",
    "\n",
    "        if isValSet_bool:\n",
    "            assert val_stride > 0, val_stride\n",
    "            self.candidateInfo_list = self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "        elif val_stride > 0:\n",
    "            del self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "\n",
    "        log.info(\"{!r}: {} {} samples\".format(\n",
    "            self,\n",
    "            len(self.candidateInfo_list),\n",
    "            \"validation\" if isValSet_bool else \"training\",\n",
    "        ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.candidateInfo_list)\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.candidateInfo_list[ndx]\n",
    "        width_irc = (32, 48, 48)\n",
    "\n",
    "        candidate_a, center_irc = getCtRawCandidate(\n",
    "            candidateInfo_tup.series_uid,\n",
    "            candidateInfo_tup.center_xyz,\n",
    "            width_irc,\n",
    "        )\n",
    "\n",
    "        candidate_t = torch.from_numpy(candidate_a)\n",
    "        candidate_t = candidate_t.to(torch.float32)\n",
    "        candidate_t = candidate_t.unsqueeze(0)\n",
    "\n",
    "        pos_t = torch.tensor([\n",
    "                not candidateInfo_tup.isNodule_bool,\n",
    "                candidateInfo_tup.isNodule_bool\n",
    "            ],\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            candidate_t,\n",
    "            pos_t,\n",
    "            candidateInfo_tup.series_uid,\n",
    "            torch.tensor(center_irc),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.5.1 geCtRawCandidate 함수로 후보 배열 캐싱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(1, typed=True)\n",
    "def getCt(series_uid):\n",
    "    return Ct(series_uid)\n",
    "\n",
    "def getCtRawCandidate(series_uid, center_xyz, width_irc):\n",
    "    ct = getCt(series_uid)\n",
    "    ct_chunk, center_irc = ct.getRawCandidate(center_xyz, width_irc)\n",
    "    return ct_chunk, center_irc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from util.disk import getCache\n",
    "from util.util import XyzTuple, xyz2irc\n",
    "from util.logconf import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "raw_cache = getCache('part2ch10_raw')\n",
    "\n",
    "CandidateInfoTuple = namedtuple(\n",
    "    'CandidateInfoTuple',\n",
    "    'isNodule_bool, diameter_mm, series_uid, center_xyz',\n",
    ")\n",
    "\n",
    "@functools.lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=True):\n",
    "    # We construct a set with all series_uids that are present on disk.\n",
    "    # This will let us use the data, even if we haven't downloaded all of\n",
    "    # the subsets yet.\n",
    "    mhd_list = glob.glob('data-unversioned/part2/luna/subset*/*.mhd')\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "\n",
    "    diameter_dict = {}\n",
    "    with open('data/part2/luna/annotations.csv', \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "            annotationCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "            annotationDiameter_mm = float(row[4])\n",
    "\n",
    "            diameter_dict.setdefault(series_uid, []).append(\n",
    "                (annotationCenter_xyz, annotationDiameter_mm)\n",
    "            )\n",
    "\n",
    "    candidateInfo_list = []\n",
    "    with open('data/part2/luna/candidates.csv', \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "\n",
    "            if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "                continue\n",
    "\n",
    "            isNodule_bool = bool(int(row[4]))\n",
    "            candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "\n",
    "            candidateDiameter_mm = 0.0\n",
    "            for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "                annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "                for i in range(3):\n",
    "                    delta_mm = abs(candidateCenter_xyz[i] - annotationCenter_xyz[i])\n",
    "                    if delta_mm > annotationDiameter_mm / 4:\n",
    "                        break\n",
    "                else:\n",
    "                    candidateDiameter_mm = annotationDiameter_mm\n",
    "                    break\n",
    "\n",
    "            candidateInfo_list.append(CandidateInfoTuple(\n",
    "                isNodule_bool,\n",
    "                candidateDiameter_mm,\n",
    "                series_uid,\n",
    "                candidateCenter_xyz,\n",
    "            ))\n",
    "\n",
    "    candidateInfo_list.sort(reverse=True)\n",
    "    return candidateInfo_list\n",
    "\n",
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(\n",
    "            'data-unversioned/part2/luna/subset*/{}.mhd'.format(series_uid)\n",
    "        )[0]\n",
    "\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "\n",
    "        # CTs are natively expressed in https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "        # HU are scaled oddly, with 0 g/cc (air, approximately) being -1000 and 1 g/cc (water) being 0.\n",
    "        # The lower bound gets rid of negative density stuff used to indicate out-of-FOV\n",
    "        # The upper bound nukes any weird hotspots and clamps bone down\n",
    "        ct_a.clip(-1000, 1000, ct_a)\n",
    "\n",
    "        self.series_uid = series_uid\n",
    "        self.hu_a = ct_a\n",
    "\n",
    "        self.origin_xyz = XyzTuple(*ct_mhd.GetOrigin())\n",
    "        self.vxSize_xyz = XyzTuple(*ct_mhd.GetSpacing())\n",
    "        self.direction_a = np.array(ct_mhd.GetDirection()).reshape(3, 3)\n",
    "\n",
    "    def getRawCandidate(self, center_xyz, width_irc):\n",
    "        center_irc = xyz2irc(\n",
    "            center_xyz,\n",
    "            self.origin_xyz,\n",
    "            self.vxSize_xyz,\n",
    "            self.direction_a,\n",
    "        )\n",
    "\n",
    "        slice_list = []\n",
    "        for axis, center_val in enumerate(center_irc):\n",
    "            start_ndx = int(round(center_val - width_irc[axis]/2))\n",
    "            end_ndx = int(start_ndx + width_irc[axis])\n",
    "\n",
    "            assert center_val >= 0 and center_val < self.hu_a.shape[axis], repr([self.series_uid, center_xyz, self.origin_xyz, self.vxSize_xyz, center_irc, axis])\n",
    "\n",
    "            if start_ndx < 0:\n",
    "                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n",
    "                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n",
    "                start_ndx = 0\n",
    "                end_ndx = int(width_irc[axis])\n",
    "\n",
    "            if end_ndx > self.hu_a.shape[axis]:\n",
    "                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n",
    "                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n",
    "                end_ndx = self.hu_a.shape[axis]\n",
    "                start_ndx = int(self.hu_a.shape[axis] - width_irc[axis])\n",
    "\n",
    "            slice_list.append(slice(start_ndx, end_ndx))\n",
    "\n",
    "        ct_chunk = self.hu_a[tuple(slice_list)]\n",
    "\n",
    "        return ct_chunk, center_irc\n",
    "\n",
    "\n",
    "@functools.lru_cache(1, typed=True)\n",
    "def getCt(series_uid):\n",
    "    return Ct(series_uid)\n",
    "\n",
    "@raw_cache.memoize(typed=True)\n",
    "def getCtRawCandidate(series_uid, center_xyz, width_irc):\n",
    "    ct = getCt(series_uid)\n",
    "    ct_chunk, center_irc = ct.getRawCandidate(center_xyz, width_irc)\n",
    "    return ct_chunk, center_irc\n",
    "\n",
    "class LunaDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 val_stride=0,\n",
    "                 isValSet_bool=None,\n",
    "                 series_uid=None,\n",
    "            ):\n",
    "        self.candidateInfo_list = copy.copy(getCandidateInfoList())\n",
    "\n",
    "        if series_uid:\n",
    "            self.candidateInfo_list = [\n",
    "                x for x in self.candidateInfo_list if x.series_uid == series_uid\n",
    "            ]\n",
    "\n",
    "        if isValSet_bool:\n",
    "            assert val_stride > 0, val_stride\n",
    "            self.candidateInfo_list = self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "        elif val_stride > 0:\n",
    "            del self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "\n",
    "        log.info(\"{!r}: {} {} samples\".format(\n",
    "            self,\n",
    "            len(self.candidateInfo_list),\n",
    "            \"validation\" if isValSet_bool else \"training\",\n",
    "        ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.candidateInfo_list)\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.candidateInfo_list[ndx]\n",
    "        width_irc = (32, 48, 48)\n",
    "\n",
    "        candidate_a, center_irc = getCtRawCandidate(\n",
    "            candidateInfo_tup.series_uid,\n",
    "            candidateInfo_tup.center_xyz,\n",
    "            width_irc,\n",
    "        )\n",
    "\n",
    "        candidate_t = torch.from_numpy(candidate_a)\n",
    "        candidate_t = candidate_t.to(torch.float32)\n",
    "        candidate_t = candidate_t.unsqueeze(0)\n",
    "\n",
    "        pos_t = torch.tensor([\n",
    "                not candidateInfo_tup.isNodule_bool,\n",
    "                candidateInfo_tup.isNodule_bool\n",
    "            ],\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            candidate_t,\n",
    "            pos_t,\n",
    "            candidateInfo_tup.series_uid,\n",
    "            torch.tensor(center_irc),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clim=(-1000.0, 300)\n",
    "\n",
    "def findPositiveSamples(start_ndx=0, limit=100):\n",
    "    ds = LunaDataset()\n",
    "\n",
    "    positiveSample_list = []\n",
    "    for sample_tup in ds.candidateInfo_list:\n",
    "        if sample_tup.isNodule_bool:\n",
    "            print(len(positiveSample_list), sample_tup)\n",
    "            positiveSample_list.append(sample_tup)\n",
    "\n",
    "        if len(positiveSample_list) >= limit:\n",
    "            break\n",
    "\n",
    "    return positiveSample_list\n",
    "\n",
    "def showCandidate(series_uid, batch_ndx=None, **kwargs):\n",
    "    ds = LunaDataset(series_uid=series_uid, **kwargs)\n",
    "    pos_list = [i for i, x in enumerate(ds.candidateInfo_list) if x.isNodule_bool]\n",
    "\n",
    "    if batch_ndx is None:\n",
    "        if pos_list:\n",
    "            batch_ndx = pos_list[0]\n",
    "        else:\n",
    "            print(\"Warning: no positive samples found; using first negative sample.\")\n",
    "            batch_ndx = 0\n",
    "\n",
    "    ct = Ct(series_uid)\n",
    "    ct_t, pos_t, series_uid, center_irc = ds[batch_ndx]\n",
    "    ct_a = ct_t[0].numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 50))\n",
    "\n",
    "    group_list = [\n",
    "        [9, 11, 13],\n",
    "        [15, 16, 17],\n",
    "        [19, 21, 23],\n",
    "    ]\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 1)\n",
    "    subplot.set_title('index {}'.format(int(center_irc[0])), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct.hu_a[int(center_irc[0])], clim=clim, cmap='gray')\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 2)\n",
    "    subplot.set_title('row {}'.format(int(center_irc[1])), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct.hu_a[:,int(center_irc[1])], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 3)\n",
    "    subplot.set_title('col {}'.format(int(center_irc[2])), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct.hu_a[:,:,int(center_irc[2])], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 4)\n",
    "    subplot.set_title('index {}'.format(int(center_irc[0])), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct_a[ct_a.shape[0]//2], clim=clim, cmap='gray')\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 5)\n",
    "    subplot.set_title('row {}'.format(int(center_irc[1])), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct_a[:,ct_a.shape[1]//2], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 6)\n",
    "    subplot.set_title('col {}'.format(int(center_irc[2])), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct_a[:,:,ct_a.shape[2]//2], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    for row, index_list in enumerate(group_list):\n",
    "        for col, index in enumerate(index_list):\n",
    "            subplot = fig.add_subplot(len(group_list) + 2, 3, row * 3 + col + 7)\n",
    "            subplot.set_title('slice {}'.format(index), fontsize=30)\n",
    "            for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "                label.set_fontsize(20)\n",
    "            plt.imshow(ct_a[index], clim=clim, cmap='gray')\n",
    "\n",
    "\n",
    "    print(series_uid, batch_ndx, bool(pos_t[0]), pos_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateInfo_list = getCandidateInfoList(requireOnDisk_bool=False)\n",
    "positiveInfo_list = [x for x in candidateInfo_list if x[0]]\n",
    "diameter_list = [x[1] for x in positiveInfo_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 32.3 mm\n",
      " 100 17.7 mm\n",
      " 200 13.0 mm\n",
      " 300 10.0 mm\n",
      " 400  8.2 mm\n",
      " 500  7.0 mm\n",
      " 600  6.3 mm\n",
      " 700  5.7 mm\n",
      " 800  5.1 mm\n",
      " 900  4.7 mm\n",
      "1000  4.0 mm\n",
      "1100  0.0 mm\n",
      "1200  0.0 mm\n",
      "1300  0.0 mm\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(diameter_list), 100):\n",
    "    print(\"{:4} {:4.1f} mm\".format(i, diameter_list[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.5.4 데이터 렌더링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:29:49,507 INFO     pid:36084 __main__:170:__init__ <__main__.LunaDataset object at 0x0000020868C23220>: 0 training samples\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "positiveSample_list = findPositiveSamples()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 종양 탐지를 위한 분류 모델 훈련 \n",
    "\n",
    "### 11.1 기본 모델과 훈련 루프\n",
    "- 모델을 초기화하고 데이터를 로딩\n",
    "\n",
    "### 11.2 애플리케이션의 메인 진입점\n",
    "이후 과정들은 제공되는 코드들 이용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6170c7e636c2dbd0f88cb8f557866518ac6c7d83ee4f2709c7df3161954bfcc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
